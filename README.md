# Syzygy-of-thoughts
ğŸš€ **Hello, [ç¤¾äº¤å¹³å°è´¦å·](https://www.youtube.com/watch?v=gZABle836yM)**  
- xxxxxxxxxxxxxxxxxxxxxxx

<div align='left'>
<img src="assets/rader.png" alt="teaser" width="400" />
</div>
æœ¬é¡¹ç›®ä¸ºè®ºæ–‡ã€ŠSyzygy of Thoughts: Enhancing LLM Reasoning with Minimal Free Resolutionã€‹çš„ä»£ç å®ç°ã€‚è¯¥è®ºæ–‡æå‡ºäº†ä¸€ç§æ–°é¢–çš„æ¨ç†æ¡†æ¶ Syzygy of Thoughts (SoT)ï¼Œé€šè¿‡å°†äº¤æ¢ä»£æ•°ä¸åŒè°ƒä»£æ•°ä¸­çš„ æœ€å°è‡ªç”±åˆ†è§£ (Minimal Free Resolution, MFR) åŸç†èå…¥æ€ç»´é“¾ (Chain of Thought, CoT)ï¼Œæ˜¾è‘—æå‡å¤§å‹è¯­è¨€æ¨¡å‹ (LLM) åœ¨å¤æ‚æ¨ç†ä»»åŠ¡ä¸­çš„æ€§èƒ½ã€‚SoT é’ˆå¯¹ä¼ ç»Ÿ CoT åœ¨é«˜ç»´ã€éçº¿æ€§æ¨ç†ä¸­çš„å±€é™ï¼Œå¼•å…¥æ¨¡å—ã€è‡ªç”±æ€§ã€æ˜ å°„ã€ç²¾ç¡®æ€§ã€æœ€å°æ€§å’Œ Betti æ•°ç­‰ç»“æ„åŒ–åˆ†è§£ç­–ç•¥ï¼Œå°†å¤æ‚é—®é¢˜è½¬åŒ–ä¸ºç´§å‡‘ä¸”é€»è¾‘è‡ªæ´½çš„æ¨ç†å•å…ƒã€‚
å®éªŒåœ¨ GSM8K å’Œ MATH ç­‰æ•°æ®é›†ä¸Šè¿›è¡Œï¼Œæ¶µç›– GPT-4o-miniã€Qwen2.5 ç­‰æ¨¡å‹ï¼ŒSoT çš„æ¨ç†å‡†ç¡®ç‡è¾¾åˆ°æˆ–è¶…è¶Šä¸»æµ CoT æ ‡å‡†ï¼ˆä¾‹å¦‚ï¼ŒGSM8K 96.0%ï¼ŒMATH 79.1%ï¼‰ï¼Œä¸”åœ¨é«˜æ¸©æ¡ä»¶ä¸‹ä¿æŒç¨³å®šæ€§ï¼Œæ¨ç†æ—¶é—´æ›´å…·å¯æ‰©å±•æ€§ã€‚


<div align='left'>
<img src="assets/main.png" alt="teaser" width="800" />
</div>


## Highlight## 

æœ¬é¡¹ç›®å®ç°äº†ã€ŠSyzygy of Thoughtsã€‹è®ºæ–‡ä¸­çš„ SoT æ¨ç†æ¡†æ¶ï¼ŒåŒ…å«æ•°æ®é›†ã€æ¨¡å‹é…ç½®ã€æºä»£ç å’Œå®éªŒç»“æœã€‚ä»¥ä¸‹æ˜¯é¡¹ç›®ç›®å½•ç»“æ„ï¼š

```plaintext
SoT-Paper-Code/
â”œâ”€â”€ **data/**                     # æ•°æ®é›†å­˜æ”¾ç›®å½•
â”‚   â”œâ”€â”€ gsm8k/                    # GSM8K æ•°å­¦æ¨ç†æ•°æ®é›†
â”‚   â”œâ”€â”€ math/                     # MATH é«˜çº§æ•°å­¦æ•°æ®é›†
â”‚   â”œâ”€â”€ svamp/                    # SVAMP æ•°å­¦æ¨ç†æ•°æ®é›†
â”‚   â””â”€â”€ others/                   # å…¶ä»–æ•°æ®é›†ï¼ˆMultiArithã€ASDivã€AQUA ç­‰ï¼‰
â”œâ”€â”€ **models/**                   # æ¨¡å‹é…ç½®æ–‡ä»¶ç›®å½•
â”‚   â”œâ”€â”€ gpt4o_mini/               # GPT-4o-mini æ¨¡å‹é…ç½®
â”‚   â”œâ”€â”€ qwen2.5/                  # Qwen2.5 ç³»åˆ—æ¨¡å‹é…ç½®
â”‚   â””â”€â”€ gemma/                    # Gemma æ¨¡å‹é…ç½®
â”œâ”€â”€ **src/**                      # æºä»£ç ç›®å½•
â”‚   â”œâ”€â”€ **sot.py**                # SoT æ¨ç†æ¡†æ¶æ ¸å¿ƒå®ç°
â”‚   â”œâ”€â”€ cot.py                    # CoT åŸºçº¿æ¨ç†å®ç°
â”‚   â”œâ”€â”€ cot_sc.py                 # CoT-SC (n=5) æ¨ç†å®ç°
â”‚   â”œâ”€â”€ mfr_utils.py              # æœ€å°è‡ªç”±åˆ†è§£å·¥å…·å‡½æ•°
â”‚   â””â”€â”€ evaluate.py               # æ€§èƒ½è¯„ä¼°è„šæœ¬
â”œâ”€â”€ **experiments/**              # å®éªŒç»“æœä¸å¯è§†åŒ–
â”‚   â”œâ”€â”€ figures/                  # å®éªŒå›¾è¡¨ï¼ˆæŠ˜çº¿å›¾ã€ç®±å‹å›¾ç­‰ï¼‰
â”‚   â””â”€â”€ logs/                     # å®éªŒè¿è¡Œæ—¥å¿—
â”œâ”€â”€ **requirements.txt**          # é¡¹ç›®ä¾èµ–ç¯å¢ƒé…ç½®
â”œâ”€â”€ **README.md**                 # é¡¹ç›®è¯´æ˜æ–‡æ¡£
â””â”€â”€ run.sh                        # ä¸€é”®è¿è¡Œè„šæœ¬s
SoT-Paper-Code/
â”œâ”€â”€ data/                     # æ•°æ®é›†æ–‡ä»¶
â”‚   â”œâ”€â”€ gsm8k/                # GSM8K æ•°æ®é›†
â”‚   â”œâ”€â”€ math/                 # MATH æ•°æ®é›†
â”‚   â”œâ”€â”€ svamp/                # SVAMP æ•°æ®é›†
â”‚   â””â”€â”€ others/               # å…¶ä»–æ•°æ®é›†ï¼ˆMultiArith, ASDiv, AQUA ç­‰ï¼‰
â”œâ”€â”€ models/                   # æ¨¡å‹é…ç½®æ–‡ä»¶
â”‚   â”œâ”€â”€ gpt4o_mini/           # GPT-4o-mini é…ç½®
â”‚   â”œâ”€â”€ qwen2.5/              # Qwen2.5 é…ç½®
â”‚   â””â”€â”€ gemma/                # Gemma æ¨¡å‹é…ç½®
â”œâ”€â”€ src/                      # æºä»£ç 
â”‚   â”œâ”€â”€ sot.py                # SoT æ¨ç†æ¡†æ¶å®ç°
â”‚   â”œâ”€â”€ cot.py                # CoT åŸºçº¿å®ç°
â”‚   â”œâ”€â”€ cot_sc.py             # CoT-SC (n=5) å®ç°
â”‚   â”œâ”€â”€ mfr_utils.py          # MFR å·¥å…·å‡½æ•°
â”‚   â””â”€â”€ evaluate.py           # è¯„ä¼°è„šæœ¬
â”œâ”€â”€ experiments/              # å®éªŒç»“æœä¸å¯è§†åŒ–
â”‚   â”œâ”€â”€ figures/              # å›¾è¡¨ï¼ˆæŠ˜çº¿å›¾ã€ç®±å‹å›¾ï¼‰
â”‚   â””â”€â”€ logs/                 # å®éªŒæ—¥å¿—
â”œâ”€â”€ requirements.txt          # ä¾èµ–ç¯å¢ƒ
â”œâ”€â”€ README.md                 # é¡¹ç›®è¯´æ˜
â””â”€â”€ run.sh                    # è¿è¡Œè„šæœ¬
```



## Overview
- [Schedule](#schedule)
- [Citation](#citation)
- [Installation](#installation)
- [API Configuration Setup](#api-configuration-setup)
- [Data Preparation](#data-preparation)
- [Quick Start](#quick-start)
- [Model Zoo](#model-zoo)


## Schedule
ä»‹ç»xxxxxx:
- [x] xxx
- [x] xxx
  - [x] xxx
  - [x] xxx
  - [x] xxx


## Citation
If you find SoT useful to your research, please cite our work as an acknowledgment.(*^â–½^*)
```bib

```


## Installation

### 1.å…‹éš†é¡¹ç›®ä»“åº“

é¦–å…ˆï¼Œå°†é¡¹ç›®ä»“åº“å…‹éš†åˆ°æœ¬åœ°ã€‚æ‰“å¼€ç»ˆç«¯æˆ–å‘½ä»¤æç¤ºç¬¦ï¼Œæ‰§è¡Œä»¥ä¸‹å‘½ä»¤ï¼š

```
git clone https://github.com/piotrkawa/audio-deepfake-source-tracing.git
cd audio-deepfake-source-tracing
```
### 2.åˆ›å»ºè™šæ‹Ÿç¯å¢ƒï¼ˆå¯é€‰ä½†æ¨èï¼‰

ä¸ºé¿å…é¡¹ç›®ä¾èµ–ä¸ç³»ç»Ÿç¯å¢ƒä¸­çš„å…¶ä»– Python åŒ…å†²çªï¼Œå»ºè®®ä½¿ç”¨è™šæ‹Ÿç¯å¢ƒã€‚å¯ä½¿ç”¨venvï¼ˆPython å†…ç½®çš„è™šæ‹Ÿç¯å¢ƒå·¥å…·ï¼‰æ¥åˆ›å»ºå’Œç®¡ç†è™šæ‹Ÿç¯å¢ƒã€‚

```
æ¨èä½¿ç”¨anacondaè¿›è¡Œç¯å¢ƒç®¡ç†
#åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ
conda create -n venv pyrhon=3.9

#æ¿€æ´»è™šæ‹Ÿç¯å¢ƒ
conda activate venv

# åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ
python -m venv venv python=3.9

# æ¿€æ´»è™šæ‹Ÿç¯å¢ƒ
# åœ¨Windowsä¸Š
.\venv\Scripts\activate
# åœ¨Linux/Macä¸Š
source venv/bin/activate
```

### 3.å®‰è£…é¡¹ç›®ä¾èµ–

é¡¹ç›®ä¾èµ–åº“ä¿¡æ¯è®°å½•åœ¨requirements.txtæ–‡ä»¶ä¸­ï¼Œä½¿ç”¨pipå®‰è£…è¿™äº›ä¾èµ–ï¼š

```
pip install -r requirements.txt
```

### 4.æ•°æ®å‡†å¤‡
é¡¹ç›®æä¾›äº†å®éªŒä½¿ç”¨çš„æ•°æ®é›†ä»¥åŠç›®å‰å¹¿ä¸ºä½¿ç”¨çš„æ•°æ®é›†ï¼Œæ–¹ä¾¿æ‚¨è¿›è¡Œè‡ªå·±çš„å®éªŒå’Œè¿è¡Œæˆ‘ä»¬çš„ä»£ç 
é¡¹ç›®é»˜è®¤æ•°æ®é›†è·¯å¾„åœ¨sot.yamlæ–‡ä»¶çš„runner.default_datasetå­—æ®µä¸­æŒ‡å®šï¼Œç¡®ä¿è¯¥è·¯å¾„ä¸‹çš„æ•°æ®é›†æ–‡ä»¶å­˜åœ¨ã€‚è‹¥è¦ä½¿ç”¨å…¶ä»–æ•°æ®é›†ï¼Œå¯ä¿®æ”¹è¯¥å­—æ®µçš„å€¼

### 5.è¿è¡Œé¡¹ç›®
å®‰è£…å®Œæˆåï¼Œå¯æŒ‰ç…§ä»¥ä¸‹å‘½ä»¤è¿è¡Œé¡¹ç›®ï¼š
```
python main.py
```

## å¸¸è§é—®é¢˜åŠè§£å†³æ–¹æ³•
## 1.ä¾èµ–å®‰è£…å¤±è´¥
ç¡®ä¿ç½‘ç»œè¿æ¥æ­£å¸¸ï¼Œå¹¶ä¸”requirements.txtæ–‡ä»¶ä¸­çš„ä¾èµ–ç‰ˆæœ¬ä¸ Python ç‰ˆæœ¬å…¼å®¹ã€‚å¯å°è¯•æ‰‹åŠ¨å®‰è£…æ¯ä¸ªä¾èµ–ï¼Œæˆ–è€…æ›´æ–°pipåˆ°æœ€æ–°ç‰ˆæœ¬ï¼š

```
pip install --upgrade pip
```
### 2.è™šæ‹Ÿç¯å¢ƒæ¿€æ´»å¤±è´¥
ç¡®ä¿ä½¿ç”¨çš„å‘½ä»¤ä¸æ“ä½œç³»ç»Ÿå…¼å®¹ã€‚åœ¨ Windows ä¸Šä½¿ç”¨ PowerShell æ—¶ï¼Œå¯èƒ½éœ€è¦ä»¥ç®¡ç†å‘˜èº«ä»½è¿è¡Œ PowerShell æ‰èƒ½æ¿€æ´»è™šæ‹Ÿç¯å¢ƒã€‚
### 3.æ•°æ®é›†åŠ è½½å¤±è´¥
æ£€æŸ¥sot.yamlæ–‡ä»¶ä¸­çš„runner.default_datasetè·¯å¾„æ˜¯å¦æ­£ç¡®ï¼Œä»¥åŠæ•°æ®é›†æ–‡ä»¶æ ¼å¼æ˜¯å¦ç¬¦åˆè¦æ±‚ï¼ˆé€šå¸¸ä¸º JSON æˆ– JSONL æ ¼å¼ï¼‰ã€‚
## API Configuration Setup

Before using the Syzygy-of-thoughts (SoT) framework, you need to set up your API key and URL:

1. Create an `Syzygy-of-thoughts/config/sot.yaml` file in the project root directory with the following format:

```
url = "https://api.openai.com/v1"  # Replace with your API endpoint
api_key = [
    "your-api-key-here",  # Replace with your actual API key
    # You can add multiple API keys to improve concurrency performance.
]
```

### è·å– API Key

è¯·æ ¹æ®ä¸‹åˆ—å¹³å°è·å–æ‚¨çš„ API Keyï¼š

- **ChatGPT**: [æ³¨å†Œå¹¶è·å– API Key](https://platform.openai.com/signup)
- **Qwen (é€šä¹‰åƒé—®)**: [ç™»å½•å¹¶è·å– API Key](https://bailian.console.aliyun.com/?tab=model#/api-key)
- **Gemma**: [åˆ›å»ºè´¦æˆ·å¹¶è·å– API Key](https://www.netmind.ai/user/apiToken)

è·å– API Key åï¼Œæ‚¨å¯ä»¥å°†å…¶é…ç½®åˆ°é¡¹ç›®ä¸­ä»¥å¯ç”¨ç›¸å…³åŠŸèƒ½ã€‚



### Requirements
 Syzygy-of-thoughts :

(Recommendation)
- Ubuntu: 
- CUDA: 
- PyTorch: 

### Environment
# æ”¹æˆæˆ‘ä»¬è‡ªå·±çš„

## Data Preparation
Please further refer xxx

## Quick Start
xxxxxxxxxxxxx


## Model Zoo
### 1. å®éªŒæ€§èƒ½
ä»¥ä¸‹è¡¨æ ¼æ¯”è¾ƒäº† CoTã€CoT-SC (n=5) å’Œ SoT åœ¨å¤šç§ä»»åŠ¡ä¸Šçš„æ€§èƒ½ï¼Œæ¶µç›–æ•°å­¦æ¨ç†ï¼ˆGSM8Kã€SVAMPã€MultiArithã€ASDivã€AQUAï¼‰ã€é€šç”¨çŸ¥è¯†ï¼ˆMMLUï¼‰ã€å¤šä»»åŠ¡é—®ç­”ï¼ˆBBHï¼‰ã€æ—¶é—´æ¨ç†ï¼ˆDateï¼‰å’Œé€»è¾‘æ¨ç†ï¼ˆCLUTRRï¼‰ã€‚SoT åœ¨æ‰€æœ‰æ¨¡å‹å’Œä»»åŠ¡ä¸­å‡å–å¾—æœ€ä½³è¡¨ç°ã€‚
| **Method**                        | **GSM8K** | **SVAMP** | **MultiArith** | **ASDiv** | **AQUA** | **MMLU** | **BBH** | **Date** | **CLUTRR** |
|------------------------------------|:---------:|:---------:|:--------------:|:---------:|:--------:|:--------:|:-------:|:--------:|:----------:|
| **GPT-4o-mini**                    |           |           |                |           |          |          |         |          |            |
| CoT                                | 85.1%     | 84.4%     | 99.2%          | 97.0%     | 65.0%    | 63.1%    | 66.3%   | 51.8%    | 65.9%      |
| CoT-SC (n=5)                       | 90.1%     | 86.0%     | 99.5%          | 98.5%     | 70.9%    | 67.3%    | 69.2%   | 54.9%    | 72.4%      |
| **SoT (Ours)**                     | **96.0%** | **92.2%** | **99.7%**      | **99.8%** | **75.6%** | **75.2%** | **72.8%** | **75.2%** | **75.7%**  |
| **Qwen2.5-Coder-7B-Instruct**      |           |           |                |           |          |          |         |          |            |
| CoT                                | 77.2%     | 82.4%     | 92.3%          | 92.0%     | 60.6%    | 55.1%    | 47.1%   | 31.0%    | 20.1%      |
| CoT-SC (n=5)                       | 80.2%     | 84.1%     | 95.0%          | 95.0%     | 62.2%    | 56.3%    | 49.3%   | 32.9%    | 21.0%      |
| **SoT (Ours)**                     | **89.1%** | **90.6%** | **97.0%**      | **99.8%** | **63.3%** | **57.1%** | **57.3%** | **36.2%** | **26.3%**  |
| **Qwen2.5-VL-72B-Instruct**        |           |           |                |           |          |          |         |          |            |
| CoT                                | 86.1%     | 86.9%     | 98.8%          | 98.0%     | 81.1%    | 80.1%    | 77.3%   | 75.2%    | 70.1%      |
| CoT-SC (n=5)                       | 89.1%     | 88.2%     | 99.3%          | 98.4%     | 83.9%    | 82.9%    | 79.0%   | 78.0%    | 75.0%      |
| **SoT (Ours)**                     | **96.0%** | **95.8%** | **99.7%**      | **99.2%** | **89.4%** | **84.3%** | **85.3%** | **80.2%** | **78.9%**  |
| **Gemma-3-27b-it**                 |           |           |                |           |          |          |         |          |            |
| CoT                                | 83.1%     | 85.9%     | 91.9%          | 98.5%     | 80.3%    | 70.8%    | 70.7%   | 76.9%    | 65.3%      |
| CoT-SC (n=5)                       | 87.1%     | 87.0%     | 92.3%          | 99.2%     | 85.4%    | 73.2%    | 73.2%   | 80.2%    | 66.4%      |
| **SoT (Ours)**                     | **96.0%** | **95.8%** | **99.7%**      | **99.2%** | **89.4%** | **84.3%** | **85.3%** | **80.2%** | **78.9%**  |
| **Gemma-3-12b-it**                 |           |           |                |           |          |          |         |          |            |
| CoT                                | 83.2%     | 79.0%     | 90.4%          | 97.7%     | 68.9%    | 68.1%    | 64.6%   | 77.7%    | 49.0%      |
| CoT-SC (n=5)                       | 86.1%     | 81.0%     | 93.3%          | 98.0%     | 71.7%    | 70.6%    | 66.7%   | 80.2%    | 52.2%      |
| **SoT (Ours)**                     | **92.1%** | **92.5%** | **96.1%**      | **99.2%** | **77.2%** | **72.3%** | **69.1%** | **82.5%** | **55.0%**  |






